# External Resources & References

This document provides curated external references for technologies, models, and concepts used in this repository.

## Core Technologies

### n8n Workflow Automation

- **Official Site:** <https://n8n.io/>
- **GitHub:** <https://github.com/n8n-io/n8n>
- **Workflows:** <https://n8n.io/workflows/>
- **Description:** Fair-code workflow automation with 400+ integrations and native AI capabilities

### Ollama

- **Official Site:** <https://ollama.com/>
- **Documentation:** <https://ollama.com/docs>
- **GitHub:** <https://github.com/ollama/ollama>
- **Description:** Run large language models locally

### Langfuse

- **Official Site:** <https://langfuse.com/>
- **GitHub:** <https://github.com/langfuse/langfuse>
- **Documentation:** <https://langfuse.com/docs/tracing>
- **Description:** Open source LLM observability platform with tracing, metrics, and prompt management

### pgvector

- **GitHub:** <https://github.com/pgvector/pgvector>
- **Description:** Open-source vector similarity search extension for PostgreSQL

______________________________________________________________________

## Language Models

### GPT-OSS (September 2025)

- **Ollama Blog:** <https://ollama.com/blog/gpt-oss>
- **OpenAI Announcement:** <https://openai.com/index/introducing-gpt-oss/>
- **Key Features:** 21B params (3.6B active MoE), MXFP4 quantization, 100K+ context on 24GB VRAM

### DeepSeek-R1

- **HuggingFace:** <https://huggingface.co/deepseek-ai/DeepSeek-R1>
- **GitHub:** <https://github.com/deepseek-ai/DeepSeek-R1>
- **Complete Guide:** <https://www.bentoml.com/blog/the-complete-guide-to-deepseek-models-from-v3-to-r1-and-beyond>
- **DataCamp Overview:** <https://www.datacamp.com/blog/deepseek-r1>

### Qwen3

- **Official Blog:** <https://qwenlm.github.io/blog/qwen3/>
- **GitHub:** <https://github.com/QwenLM/Qwen3>
- **Specifications:** <https://blog.galaxy.ai/model/qwen3-max>

### Microsoft Phi-4-mini

- **HuggingFace:** <https://huggingface.co/microsoft/Phi-4-mini-instruct>
- **Official Site:** <https://azure.microsoft.com/en-us/products/phi>
- **Ollama Library:** <https://ollama.com/library/phi4-mini>
- **Announcement:**
  <https://techcommunity.microsoft.com/blog/educatordeveloperblog/welcome-to-the-new-phi-4-models---microsoft-phi-4-mini--phi-4-multimodal/4386037>

### Nomic Embed Text

- **Official Blog:** <https://www.nomic.ai/blog/posts/nomic-embed-text-v1>
- **HuggingFace:** <https://huggingface.co/nomic-ai/nomic-embed-text-v1>
- **Ollama Library:** <https://ollama.com/library/nomic-embed-text>
- **V2 Release:** <https://www.nomic.ai/blog/posts/nomic-embed-text-v2>

______________________________________________________________________

## Technical Concepts

### RAG (Retrieval-Augmented Generation)

- **AWS Overview:** <https://aws.amazon.com/what-is/retrieval-augmented-generation/>
- **NVIDIA Blog:** <https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/>
- **Google Cloud:** <https://cloud.google.com/use-cases/retrieval-augmented-generation>
- **IBM Guide:** <https://www.ibm.com/think/topics/retrieval-augmented-generation>

### LLM Quantization

- **Detailed Guide:**
  <https://medium.com/@paul.ilvez/demystifying-llm-quantization-suffixes-what-q4-k-m-q8-0-and-q6-k-really-mean-0ec2770f17d3>
- **HuggingFace:** <https://huggingface.co/docs/optimum/en/concept_guides/quantization>
- **Visual Guide:** <https://smcleod.net/2024/07/understanding-ai/llm-quantisation-through-interactive-visualisations/>

______________________________________________________________________

## Hardware Benchmarks

### RTX 4090 Performance

- **Ollama Benchmark:** <https://www.databasemart.com/blog/ollama-gpu-benchmark-rtx4090>
- **Puget Systems LLM Inference:** <https://www.pugetsystems.com/labs/articles/llm-inference-consumer-gpu-performance/>
- **vLLM Benchmark:** <https://www.databasemart.com/blog/vllm-gpu-benchmark-rtx4090>
- **GitHub Benchmark Collection:** <https://github.com/XiongjieDai/GPU-Benchmarks-on-LLM-Inference>

______________________________________________________________________

## Community Integrations

### Brave Search + n8n

- **Official Guide:** <https://brave.com/search/api/guides/use-with-n8n/>
- **GitHub Node:** <https://github.com/brave/n8n-nodes-brave-search>
- **n8n Integration:** <https://n8n.io/integrations/brave-search/>
- **Brave Search API:** <https://brave.com/search/api/>

### n8n Workflow Templates

- **Web Search Chatbot:** <https://n8n.io/workflows/3189-build-a-web-search-chatbot-with-gpt-4o-and-mcp-brave-search/>
- **Intelligent Search:**
  <https://n8n.io/workflows/4559-intelligent-web-and-local-search-with-brave-search-api-and-google-gemini-mcp-server/>

______________________________________________________________________

## Learning Resources

### Getting Started

- **Ollama Documentation:** <https://ollama.com/docs>
- **n8n Workflows Library:** <https://n8n.io/workflows/>
- **Model Selection:** <https://ollama.com/library>
- **Langfuse Tracing Docs:** <https://langfuse.com/docs/tracing>

### Advanced Topics

- **PostgreSQL pgvector Guide:** <https://github.com/pgvector/pgvector>
- **Model Quantization Deep Dive:** <https://huggingface.co/docs/optimum/en/concept_guides/quantization>
- **RAG Best Practices:** <https://aws.amazon.com/what-is/retrieval-augmented-generation/>
- **GPU Optimization:** <https://www.pugetsystems.com/labs/articles/llm-inference-consumer-gpu-performance/>

______________________________________________________________________

## Additional References

### Cloud Pricing (for comparison)

- **OpenAI Pricing:** <https://openai.com/api/pricing/>
- **Anthropic Pricing:** <https://www.anthropic.com/pricing>

### Community & Support

- **n8n Community:** <https://community.n8n.io/>
- **Ollama Discord:** <https://discord.gg/ollama>
- **Langfuse Discord:** <https://discord.gg/langfuse>
